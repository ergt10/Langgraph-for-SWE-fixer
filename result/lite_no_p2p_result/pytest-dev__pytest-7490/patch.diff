
diff --git a/src/_pytest/skipping.py b/src/_pytest/skipping.py
index 1316da9..3995502 100644
--- a/src/_pytest/skipping.py
+++ b/src/_pytest/skipping.py
@@ -6,9 +6,11 @@ import traceback
 from typing import Generator
 from typing import Optional
 from typing import Tuple
+from typing import Union
 
 import attr
 
+
 from _pytest.compat import TYPE_CHECKING
 from _pytest.config import Config
 from _pytest.config import hookimpl

diff --git a/src/_pytest/skipping.py b/src/_pytest/skipping.py
index 1316da9..5054b2d 100644
--- a/src/_pytest/skipping.py
+++ b/src/_pytest/skipping.py
@@ -194,10 +194,11 @@ class Xfail:
     reason = attr.ib(type=str)
     run = attr.ib(type=bool)
     strict = attr.ib(type=bool)
-    raises = attr.ib(type=Optional[Tuple["Type[BaseException]", ...]])
+    raises = attr.ib(type=Optional[Union[None, Tuple["Type[BaseException]", ...]]])
 
 
 def evaluate_xfail_marks(item: Item) -> Optional[Xfail]:
+
     """Evaluate xfail marks on item, returning Xfail if triggered."""
     for mark in item.iter_markers(name="xfail"):
         run = mark.kwargs.get("run", True)

diff --git a/src/_pytest/skipping.py b/src/_pytest/skipping.py
index 1316da9..a6aa74f 100644
--- a/src/_pytest/skipping.py
+++ b/src/_pytest/skipping.py
@@ -238,22 +238,26 @@ def pytest_runtest_setup(item: Item) -> None:
         item._store[skipped_by_mark_key] = True
         skip(skipped.reason)
 
+    item._store[xfailed_key] = None
+
     if not item.config.option.runxfail:
-        item._store[xfailed_key] = xfailed = evaluate_xfail_marks(item)
+        xfailed = evaluate_xfail_marks(item)
         if xfailed and not xfailed.run:
             xfail("[NOTRUN] " + xfailed.reason)
 
 
 @hookimpl(hookwrapper=True)
 def pytest_runtest_call(item: Item) -> Generator[None, None, None]:
-    xfailed = item._store.get(xfailed_key, None)
-    if xfailed is None:
-        item._store[xfailed_key] = xfailed = evaluate_xfail_marks(item)
+    if item._store.get(xfailed_key, None) is None:
+        item._store[xfailed_key] = evaluate_xfail_marks(item)
+
+    xfailed = item._store[xfailed_key]
 
     if not item.config.option.runxfail:
         if xfailed and not xfailed.run:
             xfail("[NOTRUN] " + xfailed.reason)
 
+
     yield
 
 

diff --git a/src/_pytest/skipping.py b/src/_pytest/skipping.py
index 1316da9..95002f0 100644
--- a/src/_pytest/skipping.py
+++ b/src/_pytest/skipping.py
@@ -261,10 +261,16 @@ def pytest_runtest_call(item: Item) -> Generator[None, None, None]:
 def pytest_runtest_makereport(item: Item, call: CallInfo[None]):
     outcome = yield
     rep = outcome.get_result()
-    xfailed = item._store.get(xfailed_key, None)
+
+    if item._store.get(xfailed_key, None) is None:
+        item._store[xfailed_key] = xfailed = evaluate_xfail_marks(item)
+    else:
+        xfailed = item._store[xfailed_key]
+
     # unittest special case, see setting of unexpectedsuccess_key
     if unexpectedsuccess_key in item._store and rep.when == "call":
         reason = item._store[unexpectedsuccess_key]
+
         if reason:
             rep.longrepr = "Unexpected success: {}".format(reason)
         else:
